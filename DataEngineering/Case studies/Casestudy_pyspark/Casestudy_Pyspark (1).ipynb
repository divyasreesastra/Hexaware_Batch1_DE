{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1f595d-5309-4d60-8ce0-d9afc92fc172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Loan Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/FileStore/tables/loan.csv'  \n",
    "loan_df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d7f5ca-0c52-4358-b9ef-1236b2a25e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n|     Loan Category|count|\n+------------------+-----+\n|           HOUSING|   67|\n|        TRAVELLING|   53|\n|       BOOK STORES|    7|\n|       AGRICULTURE|   12|\n|         GOLD LOAN|   77|\n|  EDUCATIONAL LOAN|   20|\n|        AUTOMOBILE|   60|\n|          BUSINESS|   24|\n|COMPUTER SOFTWARES|   35|\n|           DINNING|   14|\n|          SHOPPING|   35|\n|       RESTAURANTS|   41|\n|       ELECTRONICS|   14|\n|          BUILDING|    7|\n|        RESTAURANT|   20|\n|   HOME APPLIANCES|   14|\n+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Number of loans in each category\n",
    "loan_df.groupBy(\"Loan Category\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f690c175-08ed-4d00-b8c9-2174c01b5a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[41]: 198"
     ]
    }
   ],
   "source": [
    "# 3. Number of people with income greater than 60,000\n",
    "loan_df.filter(loan_df[\"Income\"] > 60000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d71386e4-cd8c-45dc-8ba4-5e238495a560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[46]: 137"
     ]
    }
   ],
   "source": [
    "# 4. Number of people with 2 or more returned cheques and income less than 50,000\n",
    "loan_df.filter((loan_df[\" Returned Cheque\"] >= 2) & (loan_df[\"Income\"] < 50000)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9477efe-508c-40f4-b523-c6d866fbdcf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[57]: 6"
     ]
    }
   ],
   "source": [
    "# 6. Number of people with expenditure over 50,000 a month\n",
    "loan_df.filter(loan_df[\"Expenditure\"] > 50000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65d47c8d-7b88-46fd-a2fe-13dd40df9d4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[59]: 140"
     ]
    }
   ],
   "source": [
    "# 7. Number of members who are eligible for a credit card\n",
    "\n",
    "loan_df.filter((loan_df[\"Income\"] > 40000) & (loan_df[\"Expenditure\"] >= 30000)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56822e57-792a-423f-89ba-0495a0f0c3ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Credit Card Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/FileStore/tables/credit_card.csv'  # Replace with your file path\n",
    "credit_card_df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa6c7a7-fa76-4866-8a51-330a40c0193c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[70]: 2477"
     ]
    }
   ],
   "source": [
    "# 1. Number of credit card users in Spain\n",
    "\n",
    "\n",
    "credit_card_df.filter(credit_card_df[\"Geography\"] == \"Spain\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe2e094-5e32-4cc7-97bd-a55293dff758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[100]: 832"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Number of members who are eligible and active in the bank\n",
    "\n",
    "credit_card_df.filter((credit_card_df[\"CreditScore\"] > 750) & (credit_card_df[\"IsActiveMember\"] == True)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8ad2d1-4f27-48c8-9f6f-dcd701de8bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max, min, sum, count\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Transaction Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/FileStore/tables/txn.csv'  # Replace with your file path\n",
    "txn_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "831116c9-612b-40dc-b2e1-efa8a0564002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|MaxWithdrawal|\n+-------------+\n|4.594475464E8|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#1. Maximum withdrawal amount in transactions\n",
    "\n",
    "txn_df.agg(max(\" WITHDRAWAL AMT \").alias(\"MaxWithdrawal\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "507d88d0-eb20-4e2f-9df6-c96f9566d055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------+\n|   Account No|min( WITHDRAWAL AMT )|\n+-------------+---------------------+\n|409000438611'|                  0.2|\n|     1196711'|                 0.25|\n|     1196428'|                 0.25|\n|409000493210'|                 0.01|\n|409000611074'|                120.0|\n|409000425051'|                 1.25|\n|409000405747'|                 21.0|\n|409000493201'|                  2.1|\n|409000438620'|                 0.34|\n|409000362497'|                 0.97|\n+-------------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# # 2. Minimum withdrawal amount of an account\n",
    "txn_df.groupBy(\"Account No\").min(\" WITHDRAWAL AMT \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d292abb2-90f0-46f9-8250-7b1cec2191eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|   Account No|max( DEPOSIT AMT )|\n+-------------+------------------+\n|409000438611'|          1.7025E8|\n|     1196711'|             5.0E8|\n|     1196428'|     2.119594422E8|\n|409000493210'|             1.5E7|\n|409000611074'|         3000000.0|\n|409000425051'|             1.5E7|\n|409000405747'|           2.021E8|\n|409000493201'|         1000000.0|\n|409000438620'|           5.448E8|\n|409000362497'|             2.0E8|\n+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# # 3. Maximum deposit amount of an account\n",
    "txn_df.groupBy(\"Account No\").max(\" DEPOSIT AMT \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99ba2650-8b24-479a-b059-9a80b04b9388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|   Account No|min( DEPOSIT AMT )|\n+-------------+------------------+\n|409000438611'|              0.03|\n|     1196711'|              1.01|\n|     1196428'|               1.0|\n|409000493210'|              0.01|\n|409000611074'|            1320.0|\n|409000425051'|               1.0|\n|409000405747'|             500.0|\n|409000493201'|               0.9|\n|409000438620'|              0.07|\n|409000362497'|              0.03|\n+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# # 4. Minimum deposit amount of an account\n",
    "txn_df.groupBy(\"Account No\").min(\" DEPOSIT AMT \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaf095d4-1d42-4e28-bddd-b9da4173026b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n|   Account No|    sum(BALANCE AMT)|\n+-------------+--------------------+\n|409000438611'|-2.49486577068339...|\n|     1196711'|-1.60476498101275E13|\n|     1196428'| -8.1418498130721E13|\n|409000493210'|-3.27584952132095...|\n|409000611074'|       1.615533622E9|\n|409000425051'|-3.77211841164998...|\n|409000405747'|-2.43108047067000...|\n|409000493201'|1.0420831829499985E9|\n|409000438620'|-7.12291867951358...|\n|409000362497'| -5.2860004792808E13|\n+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# # 5. Sum of balance in every bank account\n",
    "txn_df.groupBy(\"Account No\").sum(\"BALANCE AMT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe01884-165a-4027-a8cd-0fe43003dbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n|VALUE DATE|TransactionCount|\n+----------+----------------+\n| 23-Dec-16|             143|\n|  7-Feb-19|              98|\n| 21-Jul-15|              80|\n|  9-Sep-15|              91|\n| 17-Jan-15|              16|\n| 18-Nov-17|              53|\n| 21-Feb-18|              77|\n| 20-Mar-18|              71|\n| 19-Apr-18|              71|\n| 21-Jun-16|              97|\n| 17-Oct-17|             101|\n|  3-Jan-18|              70|\n|  8-Jun-18|             223|\n| 15-Dec-18|              62|\n|  8-Aug-16|              97|\n| 17-Dec-16|              74|\n|  3-Sep-15|              83|\n| 21-Jan-16|              76|\n|  4-May-18|              92|\n|  7-Sep-17|              94|\n+----------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Number of transactions on each date\n",
    "txn_df.groupBy(\"VALUE DATE\").agg(count(\"*\").alias(\"TransactionCount\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4de15634-cd75-4b37-a8f7-4a9a8100c3fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Casestudy_Pyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
