{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3340020-5c90-4a12-8b1b-34d14c36f624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">\n",
       "This module provides various utilities for users to interact with the rest of Databricks.\n",
       "  <h3></h3><b>credentials: DatabricksCredentialUtils</b> -> Utilities for interacting with credentials within notebooks<br /><b>data: DataUtils</b> -> Utilities for understanding and interacting with datasets (EXPERIMENTAL)<br /><b>fs: DbfsUtils</b> -> Manipulates the Databricks filesystem (DBFS) from the console<br /><b>jobs: JobsUtils</b> -> Utilities for leveraging jobs features<br /><b>library: LibraryUtils</b> -> Utilities for session isolated libraries<br /><b>meta: MetaUtils</b> -> Methods to hook into the compiler (EXPERIMENTAL)<br /><b>notebook: NotebookUtils</b> -> Utilities for the control flow of a notebook (EXPERIMENTAL)<br /><b>preview: Preview</b> -> Utilities under preview category<br /><b>secrets: SecretUtils</b> -> Provides utilities for leveraging secrets within notebooks<br /><b>widgets: WidgetsUtils</b> -> Methods to create and get bound value of input widgets inside notebooks<br /><br /></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65ffafb-6b0c-412a-a6cc-b514313f0bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d0aecd-3465-4e96-911e-3e780fbf8742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">/**<br /> * Copies a file or directory, possibly across FileSystems..<br /> * <br /> * Example: cp(\"/mnt/my-folder/a\", \"s3n://bucket/b\")<br /> * <br /> * @param from FileSystem URI of the source file or directory<br /> * @param to FileSystem URI of the destination file or directory<br /> * @param recurse if true, all files and directories will be recursively copied<br /> * @return true if all files were successfully copied<br /> */<br /><b>cp(from: java.lang.String, to: java.lang.String, recurse: boolean = false): boolean</b></div><br />"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">/**<br /> * Lists the contents of a directory.<br /> * <br /> * Example: display(ls(\"/mnt/my-folder/\"))<br /> * <br /> * The FileInfo object that is returned has the following helper methods:<br /> * val files = ls(\"/mnt/my-folder/\")<br /> * files.map(_.name)    // [myFile, myDir/]<br /> * files.map(_.length)  // [1286, 0]<br /> * files.map(_.path)    // [/mnt/my-folder/myFile, /mnt/my-folder/myDir/]<br /> * files.map(_.isDir)   // [false, true]<br /> * files.map(_.isFile)  // [true, false]<br /> * files.map(_.modificationTime)  // [1615937446000, 1615937224000]<br /> * <br /> * @param dir FileSystem URI<br /> * @return Ordered sequence of FileInfos containing the name, size and modification time<br /> *  of each file.<br /> */<br /><b>ls(dir: java.lang.String): scala.collection.Seq</b></div><br />"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help(\"cp\")\n",
    "dbutils.fs.help(\"ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5865f33-b273-4a1a-b65a-322e6cb6e166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/COVID/</td><td>COVID/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/README.md</td><td>README.md</td><td>976</td><td>1532502320000</td></tr><tr><td>dbfs:/databricks-datasets/Rdatasets/</td><td>Rdatasets/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/SPARK_README.md</td><td>SPARK_README.md</td><td>3359</td><td>1516124912000</td></tr><tr><td>dbfs:/databricks-datasets/adult/</td><td>adult/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/airlines/</td><td>airlines/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/amazon/</td><td>amazon/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/asa/</td><td>asa/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/atlas_higgs/</td><td>atlas_higgs/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/bikeSharing/</td><td>bikeSharing/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/cctvVideos/</td><td>cctvVideos/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/credit-card-fraud/</td><td>credit-card-fraud/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/cs100/</td><td>cs100/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/cs110x/</td><td>cs110x/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/cs190/</td><td>cs190/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/data.gov/</td><td>data.gov/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/definitive-guide/</td><td>definitive-guide/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/delta-sharing/</td><td>delta-sharing/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/flights/</td><td>flights/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/flower_photos/</td><td>flower_photos/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/flowers/</td><td>flowers/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/genomics/</td><td>genomics/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/hail/</td><td>hail/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/identifying-campaign-effectiveness/</td><td>identifying-campaign-effectiveness/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/iot/</td><td>iot/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/iot-stream/</td><td>iot-stream/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark/</td><td>learning-spark/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/</td><td>learning-spark-v2/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/lending-club-loan-stats/</td><td>lending-club-loan-stats/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/med-images/</td><td>med-images/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/media/</td><td>media/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/mnist-digits/</td><td>mnist-digits/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/news20.binary/</td><td>news20.binary/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi/</td><td>nyctaxi/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi-with-zipcodes/</td><td>nyctaxi-with-zipcodes/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/online_retail/</td><td>online_retail/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/overlap-join/</td><td>overlap-join/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/power-plant/</td><td>power-plant/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/retail-org/</td><td>retail-org/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/rwe/</td><td>rwe/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/sai-summit-2019-sf/</td><td>sai-summit-2019-sf/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/sample_logs/</td><td>sample_logs/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/samples/</td><td>samples/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/sfo_customer_survey/</td><td>sfo_customer_survey/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/sms_spam_collection/</td><td>sms_spam_collection/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/songs/</td><td>songs/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/structured-streaming/</td><td>structured-streaming/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/timeseries/</td><td>timeseries/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/tpch/</td><td>tpch/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/travel_recommendations_realtime/</td><td>travel_recommendations_realtime/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/warmup/</td><td>warmup/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/weather/</td><td>weather/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/wiki/</td><td>wiki/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/wikipedia-datasets/</td><td>wikipedia-datasets/</td><td>0</td><td>1733288714611</td></tr><tr><td>dbfs:/databricks-datasets/wine-quality/</td><td>wine-quality/</td><td>0</td><td>1733288714611</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/COVID/",
         "COVID/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/README.md",
         "README.md",
         976,
         1532502320000
        ],
        [
         "dbfs:/databricks-datasets/Rdatasets/",
         "Rdatasets/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/SPARK_README.md",
         "SPARK_README.md",
         3359,
         1516124912000
        ],
        [
         "dbfs:/databricks-datasets/adult/",
         "adult/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/airlines/",
         "airlines/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/amazon/",
         "amazon/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/asa/",
         "asa/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/atlas_higgs/",
         "atlas_higgs/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/bikeSharing/",
         "bikeSharing/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/cctvVideos/",
         "cctvVideos/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/credit-card-fraud/",
         "credit-card-fraud/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/cs100/",
         "cs100/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/cs110x/",
         "cs110x/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/cs190/",
         "cs190/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/data.gov/",
         "data.gov/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/definitive-guide/",
         "definitive-guide/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/delta-sharing/",
         "delta-sharing/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/flights/",
         "flights/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/flower_photos/",
         "flower_photos/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/flowers/",
         "flowers/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/genomics/",
         "genomics/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/hail/",
         "hail/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/identifying-campaign-effectiveness/",
         "identifying-campaign-effectiveness/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/iot/",
         "iot/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/iot-stream/",
         "iot-stream/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/learning-spark/",
         "learning-spark/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/",
         "learning-spark-v2/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/lending-club-loan-stats/",
         "lending-club-loan-stats/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/med-images/",
         "med-images/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/media/",
         "media/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/mnist-digits/",
         "mnist-digits/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/news20.binary/",
         "news20.binary/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi/",
         "nyctaxi/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi-with-zipcodes/",
         "nyctaxi-with-zipcodes/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/online_retail/",
         "online_retail/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/overlap-join/",
         "overlap-join/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/power-plant/",
         "power-plant/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/retail-org/",
         "retail-org/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/rwe/",
         "rwe/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/sai-summit-2019-sf/",
         "sai-summit-2019-sf/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/sample_logs/",
         "sample_logs/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/samples/",
         "samples/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/sfo_customer_survey/",
         "sfo_customer_survey/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/sms_spam_collection/",
         "sms_spam_collection/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/songs/",
         "songs/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/structured-streaming/",
         "structured-streaming/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/timeseries/",
         "timeseries/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/tpch/",
         "tpch/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/travel_recommendations_realtime/",
         "travel_recommendations_realtime/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/warmup/",
         "warmup/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/weather/",
         "weather/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/wiki/",
         "wiki/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/wikipedia-datasets/",
         "wikipedia-datasets/",
         0,
         1733288714611
        ],
        [
         "dbfs:/databricks-datasets/wine-quality/",
         "wine-quality/",
         0,
         1733288714611
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls /databricks-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd73897-4772-4809-b441-f2f182db43e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/databricks-datasets/COVID/.DS_Store', name='.DS_Store', size=6148, modificationTime=1615901201000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/CORD-19/', name='CORD-19/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/CSSEGISandData/', name='CSSEGISandData/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/ESRI_hospital_beds/', name='ESRI_hospital_beds/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/IHME/', name='IHME/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/USAFacts/', name='USAFacts/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/coronavirusdataset/', name='coronavirusdataset/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/covid-19-data/', name='covid-19-data/', size=0, modificationTime=1733288738332),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/download_daily_covid-19_datasets.sh', name='download_daily_covid-19_datasets.sh', size=1083, modificationTime=1609296932000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/COVID/estimated_patient_impact_and_hospital_capacity_by_state/', name='estimated_patient_impact_and_hospital_capacity_by_state/', size=0, modificationTime=1733288738332)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/databricks-datasets/COVID/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5edfecbc-04d9-42e2-a9a4-d6df133ad96d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/databricks-datasets/COVID/', name='COVID/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/README.md', name='README.md', size=976, modificationTime=1532502320000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/Rdatasets/', name='Rdatasets/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/SPARK_README.md', name='SPARK_README.md', size=3359, modificationTime=1516124912000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/adult/', name='adult/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/airlines/', name='airlines/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/amazon/', name='amazon/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/', name='asa/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/atlas_higgs/', name='atlas_higgs/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/bikeSharing/', name='bikeSharing/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cctvVideos/', name='cctvVideos/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/credit-card-fraud/', name='credit-card-fraud/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs100/', name='cs100/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs110x/', name='cs110x/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs190/', name='cs190/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/data.gov/', name='data.gov/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/definitive-guide/', name='definitive-guide/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/delta-sharing/', name='delta-sharing/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flights/', name='flights/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flower_photos/', name='flower_photos/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flowers/', name='flowers/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/genomics/', name='genomics/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/hail/', name='hail/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/identifying-campaign-effectiveness/', name='identifying-campaign-effectiveness/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/iot/', name='iot/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/iot-stream/', name='iot-stream/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/learning-spark/', name='learning-spark/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/learning-spark-v2/', name='learning-spark-v2/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/lending-club-loan-stats/', name='lending-club-loan-stats/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/med-images/', name='med-images/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/media/', name='media/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/mnist-digits/', name='mnist-digits/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/news20.binary/', name='news20.binary/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/nyctaxi/', name='nyctaxi/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/nyctaxi-with-zipcodes/', name='nyctaxi-with-zipcodes/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/online_retail/', name='online_retail/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/overlap-join/', name='overlap-join/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/power-plant/', name='power-plant/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/retail-org/', name='retail-org/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/rwe/', name='rwe/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sai-summit-2019-sf/', name='sai-summit-2019-sf/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sample_logs/', name='sample_logs/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/samples/', name='samples/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sfo_customer_survey/', name='sfo_customer_survey/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sms_spam_collection/', name='sms_spam_collection/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/songs/', name='songs/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/structured-streaming/', name='structured-streaming/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/timeseries/', name='timeseries/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/tpch/', name='tpch/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/travel_recommendations_realtime/', name='travel_recommendations_realtime/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/warmup/', name='warmup/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/weather/', name='weather/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wiki/', name='wiki/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wikipedia-datasets/', name='wikipedia-datasets/', size=0, modificationTime=1733287416186),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wine-quality/', name='wine-quality/', size=0, modificationTime=1733287416186)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"databricks-datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14174fc-4d2c-4323-a4b5-f756bfdf568f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfs:/databricks-datasets/COVID/\ndbfs:/databricks-datasets/README.md\ndbfs:/databricks-datasets/Rdatasets/\ndbfs:/databricks-datasets/SPARK_README.md\ndbfs:/databricks-datasets/adult/\ndbfs:/databricks-datasets/airlines/\ndbfs:/databricks-datasets/amazon/\ndbfs:/databricks-datasets/asa/\ndbfs:/databricks-datasets/atlas_higgs/\ndbfs:/databricks-datasets/bikeSharing/\ndbfs:/databricks-datasets/cctvVideos/\ndbfs:/databricks-datasets/credit-card-fraud/\ndbfs:/databricks-datasets/cs100/\ndbfs:/databricks-datasets/cs110x/\ndbfs:/databricks-datasets/cs190/\ndbfs:/databricks-datasets/data.gov/\ndbfs:/databricks-datasets/definitive-guide/\ndbfs:/databricks-datasets/delta-sharing/\ndbfs:/databricks-datasets/flights/\ndbfs:/databricks-datasets/flower_photos/\ndbfs:/databricks-datasets/flowers/\ndbfs:/databricks-datasets/genomics/\ndbfs:/databricks-datasets/hail/\ndbfs:/databricks-datasets/identifying-campaign-effectiveness/\ndbfs:/databricks-datasets/iot/\ndbfs:/databricks-datasets/iot-stream/\ndbfs:/databricks-datasets/learning-spark/\ndbfs:/databricks-datasets/learning-spark-v2/\ndbfs:/databricks-datasets/lending-club-loan-stats/\ndbfs:/databricks-datasets/med-images/\ndbfs:/databricks-datasets/media/\ndbfs:/databricks-datasets/mnist-digits/\ndbfs:/databricks-datasets/news20.binary/\ndbfs:/databricks-datasets/nyctaxi/\ndbfs:/databricks-datasets/nyctaxi-with-zipcodes/\ndbfs:/databricks-datasets/online_retail/\ndbfs:/databricks-datasets/overlap-join/\ndbfs:/databricks-datasets/power-plant/\ndbfs:/databricks-datasets/retail-org/\ndbfs:/databricks-datasets/rwe/\ndbfs:/databricks-datasets/sai-summit-2019-sf/\ndbfs:/databricks-datasets/sample_logs/\ndbfs:/databricks-datasets/samples/\ndbfs:/databricks-datasets/sfo_customer_survey/\ndbfs:/databricks-datasets/sms_spam_collection/\ndbfs:/databricks-datasets/songs/\ndbfs:/databricks-datasets/structured-streaming/\ndbfs:/databricks-datasets/timeseries/\ndbfs:/databricks-datasets/tpch/\ndbfs:/databricks-datasets/travel_recommendations_realtime/\ndbfs:/databricks-datasets/warmup/\ndbfs:/databricks-datasets/weather/\ndbfs:/databricks-datasets/wiki/\ndbfs:/databricks-datasets/wikipedia-datasets/\ndbfs:/databricks-datasets/wine-quality/\n"
     ]
    }
   ],
   "source": [
    "for foldername in dbutils.fs.ls(\"databricks-datasets/\"):\n",
    "    print(foldername.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb706312-f36a-48fa-a0c8-dbe5526244de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID/\nREADME.md\nRdatasets/\nSPARK_README.md\nadult/\nairlines/\namazon/\nasa/\natlas_higgs/\nbikeSharing/\ncctvVideos/\ncredit-card-fraud/\ncs100/\ncs110x/\ncs190/\ndata.gov/\ndefinitive-guide/\ndelta-sharing/\nflights/\nflower_photos/\nflowers/\ngenomics/\nhail/\nidentifying-campaign-effectiveness/\niot/\niot-stream/\nlearning-spark/\nlearning-spark-v2/\nlending-club-loan-stats/\nmed-images/\nmedia/\nmnist-digits/\nnews20.binary/\nnyctaxi/\nnyctaxi-with-zipcodes/\nonline_retail/\noverlap-join/\npower-plant/\nretail-org/\nrwe/\nsai-summit-2019-sf/\nsample_logs/\nsamples/\nsfo_customer_survey/\nsms_spam_collection/\nsongs/\nstructured-streaming/\ntimeseries/\ntpch/\ntravel_recommendations_realtime/\nwarmup/\nweather/\nwiki/\nwikipedia-datasets/\nwine-quality/\n"
     ]
    }
   ],
   "source": [
    "for foldername in dbutils.fs.ls(\"databricks-datasets/\"):\n",
    "    print(foldername.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a1747e-2a10-47e0-ba33-3e294ef7041a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1733287560846\n1532502320000\n1733287560847\n1516124912000\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n1733287560847\n"
     ]
    }
   ],
   "source": [
    "for foldername in dbutils.fs.ls(\"databricks-datasets/\"):\n",
    "    print(foldername.modificationTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f8a28bb-1977-4535-bc0b-ee157945bb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"exiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06c1197e-c2eb-4646-9c96-bc4e44fd14c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2674500560259176>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./Day5 ads\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;241m10\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:284\u001B[0m, in \u001B[0;36mDBUtils.NotebookHandler.run\u001B[0;34m(self, path, timeout_seconds, arguments, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    282\u001B[0m arguments_scala_map: Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]\n",
       "\u001B[1;32m    283\u001B[0m arguments_scala_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msc\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39mPythonUtils\u001B[38;5;241m.\u001B[39mtoScalaMap(arguments)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
       "\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mnotebook()\u001B[38;5;241m.\u001B[39mrun(\n",
       "\u001B[1;32m    285\u001B[0m     path, timeout_seconds, arguments_scala_map, __databricks_internal_cluster_spec)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n",
       "\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
       "\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o667.run.\n",
       ": com.databricks.WorkflowException: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n",
       "\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:99)\n",
       "\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n",
       "\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:147)\n",
       "\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:94)\n",
       "\t... 13 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Py4JJavaError",
        "evalue": "An error occurred while calling o667.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:99)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:147)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:94)\n\t... 13 more\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Py4JJavaError</span>: An error occurred while calling o667.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:99)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:147)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:94)\n\t... 13 more\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-2674500560259176>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./Day5 ads\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;241m10\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:284\u001B[0m, in \u001B[0;36mDBUtils.NotebookHandler.run\u001B[0;34m(self, path, timeout_seconds, arguments, *args, **kwargs)\u001B[0m\n\u001B[1;32m    282\u001B[0m arguments_scala_map: Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]\n\u001B[1;32m    283\u001B[0m arguments_scala_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msc\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39mPythonUtils\u001B[38;5;241m.\u001B[39mtoScalaMap(arguments)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mnotebook()\u001B[38;5;241m.\u001B[39mrun(\n\u001B[1;32m    285\u001B[0m     path, timeout_seconds, arguments_scala_map, __databricks_internal_cluster_spec)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
        "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o667.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:99)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.databricks.NotebookExecutionException: TIMEDOUT: Run timed out\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:147)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:94)\n\t... 13 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.notebook.run(\"./Day5 ads\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c4fa8e4-ef5f-4c87-90b6-b657c0fe376d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricks Runtime Version: 15.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check Databricks runtime version\n",
    "runtime_version = os.environ.get(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "\n",
    "if runtime_version:\n",
    "    print(f\"Databricks Runtime Version: {runtime_version}\")\n",
    "else:\n",
    "    print(\"Not running on Databricks or runtime version information is unavailable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d25b03-2d5a-4b7f-a13e-dc45fee283bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/Volume/', name='Volume/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/Volumes/', name='Volumes/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/databricks-datasets/', name='databricks-datasets/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/databricks-results/', name='databricks-results/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/volume/', name='volume/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/volumes/', name='volumes/', size=0, modificationTime=0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"FileStore/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e522f84-f9d4-410f-9e53-b9e783c9edad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volume/</td><td>Volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/Volumes/</td><td>Volumes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/volume/</td><td>volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/volumes/</td><td>volumes/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volume/",
         "Volume/",
         0,
         0
        ],
        [
         "dbfs:/Volumes/",
         "Volumes/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/",
         "databricks-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-results/",
         "databricks-results/",
         0,
         0
        ],
        [
         "dbfs:/volume/",
         "volume/",
         0,
         0
        ],
        [
         "dbfs:/volumes/",
         "volumes/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls \"dbfs:/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36453d46-666e-4679-b1bd-9b6dd5e0c68e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2674500560259181,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day6 ads",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}